---
title: "Predicting Flight Delays at PIT"
author: "Lufei Yang, Joyce Qiu"
date: "2025-04-25"
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=FALSE,
               message=FALSE, warning=FALSE, echo=FALSE,
               tidy=TRUE, tidy.opts=list(comment=FALSE))
```

# 1. Introduction
This project focuses on predicting departure delays of 15 minutes or more (`DEP_DEL15`) for flights leaving Pittsburgh International Airport (PIT). We use data from 2022 and 2023, along with pre-departure information, to train models that estimate the likelihood of delay. The final predictions are submitted for a held-out 2024 test set. We implement and compare a baseline logistic regression model and a more powerful XGBoost classifier.

# 2. Data Exploration

## 2.1 Data Overview
```{r}
library(tidyverse)
library(lubridate)
library(skimr)
library(naniar)

#skimr::skim_with(numeric = list(hist = NULL))

fl22 <- read_csv("flights2022.csv")
fl23 <- read_csv("flights2023.csv")
fl <- bind_rows(
  fl22 %>% mutate(dataset = "2022"),
  fl23 %>% mutate(dataset = "2023")
)
```

```{r, include = FALSE}
# Data dimensions
dim(fl22)
dim(fl23)

# Basic structure
glimpse(fl)

# Summary statistics
skim(fl)

# Filter to departures only
fl_departures <- fl %>% filter(ORIGIN == "PIT")
```


We worked with flight datasets from 2022 and 2023, containing commercial airline activity to and from Pittsburgh International Airport (PIT). After loading the datasets, we combined them and identified a total of 137,425 flights with 65 features per flight record. These features include scheduled and actual times, delays, airport information, carrier identifiers, and operational statistics.

A breakdown of variable types revealed 49 numeric and 16 character fields. Key variables such as `FL_DATE`, `DEP_DEL15`, `CRS_DEP_TIME`, and `OP_UNIQUE_CARRIER` provided the basis for modeling flight delays. We focused exclusively on departing flights (`ORIGIN == "PIT"`), aligning with the project objective of predicting departure delays based only on information available prior to takeoff.

## 2.2 Missingness and Class Imbalance
```{r, include = FALSE}
missings <- fl %>%
  miss_var_summary() %>%
  arrange(desc(n_miss))

fl %>%
  count(dataset, DEP_DEL15) %>%
  group_by(dataset) %>%
  mutate(pct = n / sum(n))
```

We assessed the missingness in the combined dataset and found that most core variables were well-populated, with over 97% completion. However, several post-departure variables were highly incomplete, such as `FIRST_DEP_TIME`, `TOTAL_ADD_GTIME`, and `LONGEST_ADD_GTIME`, each missing in over 99% of records. These fields, along with `CARRIER_DELAY`, `WEATHER_DELAY`, and `LATE_AIRCRAFT_DELAY` (each ~82% missing), represent information not available before departure, and were therefore excluded from feature consideration.

The response variable `DEP_DEL15` had a relatively low missing rate of ~2.5%. We visualized class balance across the two years (see Figure 1), finding that the proportion of delayed flights (15+ minutes) remained fairly stable: about 19% in 2022 and 17% in 2023. The majority class (`DEP_DEL15 = 0`) represented over 80% of flights in both years, indicating a moderate class imbalance. Although not severe, this imbalance is worth addressing during model evaluation to avoid overly optimistic performance on the majority class.

```{r, fig.show='hold', out.width = "70%"}
library(ggplot2)
library(grid)

fl <- fl %>%
  mutate(DEP_DEL15 = as.integer(DEP_DEL15))

# Check balance of the target variable
fl_departures %>%
  mutate(DEP_DEL15 = as.factor(DEP_DEL15)) %>%
  count(dataset, DEP_DEL15) %>%
  group_by(dataset) %>%
  mutate(percent = n / sum(n)) %>%
  ggplot(aes(x = DEP_DEL15, y = percent, fill = dataset)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Figure 1. Proportion of Delayed Flights by Year", x = "Departure Delay 15+ Minutes", y = "Proportion") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal()
```

## 2.3 Initial Trends and Patterns
```{r delay_rate_weekday, fig.show='hold', out.width = "70%"}
# Add temporal features
fl <- fl %>%
  mutate(
    flight_date = as.Date(FL_DATE),
    month       = factor(month(flight_date, label = TRUE), ordered = TRUE),
    weekday     = factor(wday(flight_date, label = TRUE), ordered = TRUE)
  )


# Plot delay rate by weekday
p1 <- fl %>%
  group_by(weekday) %>%
  summarise(delay_rate = mean(DEP_DEL15, na.rm=TRUE)) %>%
  ggplot(aes(x = weekday, y = delay_rate)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Delay Rate by Day of Week", x = "Day of Week", y = "P(Delay ≥15min)") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal()
```

```{r delay_rate_dep_time, fig.show='hold', out.width = "70%"}
# Plot delay rate by scheduled departure hour
p2 <- fl %>%
  group_by(DEP_TIME_BLK) %>%
  summarise(delay_rate = mean(DEP_DEL15, na.rm = TRUE), n = n()) %>%
  filter(n > 100) %>%
  ggplot(aes(x = DEP_TIME_BLK, y = delay_rate)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Delay Rate by Scheduled Departure Time Block", x = "Time Block", y = "P(Delay ≥15min)") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal()
```

```{r, fig.width = 5, fig.height = 3, out.width='80%'}
library(gridExtra)
gridExtra::grid.arrange(p1, p2, ncol = 2)
```


```{r, fig.show='hold', out.width = "70%"}
# Plot delay rate by carrier
p3 <- fl_departures %>%
  group_by(OP_UNIQUE_CARRIER) %>%
  summarize(delay_rate = mean(DEP_DEL15 == 1, na.rm = TRUE),
            n = n()) %>%
  filter(n > 50) %>%  # Only show carriers with enough flights
  ggplot(aes(x = reorder(OP_UNIQUE_CARRIER, delay_rate), y = delay_rate)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Figure 4. Delay Rate by Carrier", x = "Carrier", y = "Delay Rate") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal()
```


```{r dep_delay_by_distance, fig.show='hold', out.width = "70%"}
p4 <- fl %>%
  filter(!is.na(DEP_DELAY)) %>%
  ggplot(aes(x=factor(DISTANCE_GROUP), y=DEP_DELAY)) +
    geom_boxplot(outlier.shape=NA) +
    coord_flip() +
    labs(x="Distance Group", y="Departure Delay (min)",
         title="Figure 5. DEP_DELAY Distribution by Distance Group")
```

```{r, fig.width = 5, fig.height = 3, fig.show='hold', out.width = "80%"}
library(gridExtra)
gridExtra::grid.arrange(p3, p4, ncol = 2)
```

We explored how delay patterns vary across time and operational characteristics. As shown in Figure 2, flights on Tuesdays experienced the highest delay rates (~21%), while Wednesdays and Sundays had the lowest (~17%), suggesting midweek congestion effects.

A strong time-of-day pattern also emerged (Figure 3): morning departures (before 9 AM) had low delay rates (under 10%), while evening flights (after 6 PM) faced rates exceeding 30%, consistent with the cascading delay phenomenon.

Carrier behavior showed significant variation (Figure 4), with Frontier (F9) and Spirit (NK) exhibiting the highest delay rates, and Delta (DL) and United (UA) performing better — likely reflecting differences in operational efficiency and hub congestion.

Finally, taxi-out time was positively associated with departure delay (Figure 5), suggesting tarmac congestion as a contributing factor, even though taxi-out itself is not directly available pre-departure.

These exploratory insights informed our feature engineering choices, motivating the creation of time-of-day flags, carrier delay profiles, and route-level congestion estimates.

## 2.4 Feature Engineering

Guided by the exploratory trends, we engineered features to capture temporal patterns, carrier reliability, congestion effects, and operational context.

### Temporal Features
To reflect the variation in delay risk across the day and week (see Figures 2–3), we added flags for morning (before 9 AM), evening (after 6 PM), and peak hours (3–7 PM) based on `CRS_DEP_TIME`. We also encoded day-of-week as a categorical variable to reflect weekday-specific trends.

### Carrier Features
We included both the airline code (`OP_UNIQUE_CARRIER`) and its historical delay rate, calculated over the training set. This captures latent operational quality not reflected by the carrier ID alone (Figure 4).

### Route and Distance Features
We grouped flights by `ORIGIN-DEST` to compute historical route-level delay rates and binned flight distances using `DISTANCE_GROUP`. While `DISTANCE` was retained as a numeric variable, delay patterns by group (Figure 5) suggested additional modeling value.

### Congestion Proxies
Although `TAXI_OUT` is unavailable at prediction time, we estimated congestion by aggregating average taxi-out times by airport and time block, informed by trends in Figure 6.

### Additional Contextual Features
We also included indicators for weekends, proximity to major holidays (±2 days), and hourly flight volume as a proxy for departure congestion.

These engineered features were iteratively tested and shown to enhance performance, as later confirmed by feature importance results in Section 3.

# 3. Supervised Modeling
To predict whether a flight departing from Pittsburgh would be delayed by 15 minutes or more, we implemented both linear and non-linear classification models. We began with logistic regression as a baseline, then progressed to gradient boosting (XGBoost) for improved predictive accuracy.

## 3.1 Logistic Regression

```{r}
library(pROC)

feats <- fl %>%
  filter(!is.na(DEP_DEL15)) %>%
  transmute(
    DEP_DEL15,
    TAIL_NUM,
    flight_date = as.Date(FL_DATE, format = "%m/%d/%Y"),
    wd = factor(wday(flight_date, label = TRUE), ordered = TRUE),
    hr = CRS_DEP_TIME %/% 100,
    log_dist = log(DISTANCE),
    taxi_out = TAXI_OUT,
    carrier = OP_UNIQUE_CARRIER
  )

set.seed(42)
train_ix <- sample(nrow(feats), size = 0.7 * nrow(feats))
train <- feats[train_ix, ]
valid <- feats[-train_ix, ]

enc <- train %>%
  group_by(carrier) %>%
  summarise(carrier_rate = mean(DEP_DEL15), .groups = "drop")
base_rate <- mean(train$DEP_DEL15)

train <- left_join(train, enc, by = "carrier")
valid <- left_join(valid, enc, by = "carrier") %>%
  mutate(carrier_rate = replace_na(carrier_rate, base_rate))

mod_glm <- glm(DEP_DEL15 ~ wd + hr + log_dist + taxi_out + carrier_rate,
               data = train, family = binomial)
pred_p <- predict(mod_glm, newdata = valid, type = "response")
roc_obj <- roc(valid$DEP_DEL15, pred_p)
auc_val <- auc(roc_obj)
#cat("Logistic AUC:", round(auc_val, 4), "\n")
```
We first fit a logistic regression model using the following predictors:

- `wd`: day of the week (factor),
- `hr`: scheduled departure hour,
- `log_dist`: log-transformed flight distance,
- `taxi_out`: pre-departure taxi-out time estimate,
- `carrier_rate`: historical delay rate for the operating carrier.

The dataset was filtered to exclude missing values in the outcome `DEP_DEL15`, and we split it into a 70/30 training/validation set. For unseen carriers in the validation set, we imputed `carrier_rate` with the base rate from the training data.

The model achieved an AUC of 0.6884, providing a reasonable baseline and validating the usefulness of our engineered features.

## 3.2 XGBoost Model

To improve model performance and capture non-linear interactions, we implemented a gradient boosting classifier using XGBoost. In addition to the features used in the logistic model, we added:

- `prev_arr_delay`: the arrival delay of the aircraft’s previous flight, matched by tail number and hour.

This lag-based feature captures delay propagation due to aircraft reuse. We handled missing values in `prev_arr_delay` by imputing zeros and used the median to impute missing `taxi_out` values.

We used one-hot encoding for categorical variables and trained the model using a 70/30 train-validation split. Key hyperparameters included:

- `eta = 0.05`, `max_depth = 4`
- `subsample = 0.8`, `colsample_bytree = 0.7`
- `lambda = 1.0`, `alpha = 0.5`

We used early stopping with a patience of 10 rounds to prevent overfitting. The final model achieved an AUC of 0.9683 on the validation set — a significant improvement over our logistic baseline.


```{r, include = FALSE}
library(xgboost)
# prepare previous‐flight arrival delays
last_arr <- fl %>%
  filter(!is.na(ARR_DELAY)) %>%
  transmute(
    TAIL_NUM,
    flight_date    = as.Date(FL_DATE, format = "%m/%d/%Y"),
    hr              = CRS_DEP_TIME %/% 100,
    prev_arr_delay = ARR_DELAY
  ) %>%
  arrange(TAIL_NUM, flight_date, hr) %>%
  group_by(TAIL_NUM, flight_date, hr) %>%
  slice_tail(n = 1) %>%
  ungroup()

# merge into train/valid and impute
train2 <- train %>%
  left_join(last_arr, by = c("TAIL_NUM","flight_date","hr")) %>%
  mutate(
    prev_arr_delay = replace_na(prev_arr_delay, 0),
    taxi_out       = replace_na(taxi_out, median(taxi_out, na.rm = TRUE))
  )

valid2 <- valid %>%
  left_join(last_arr, by = c("TAIL_NUM","flight_date","hr")) %>%
  mutate(
    prev_arr_delay = replace_na(prev_arr_delay, 0),
    taxi_out       = replace_na(taxi_out, median(train2$taxi_out, na.rm = TRUE))
  )

# build model matrices
x_train <- model.matrix(~ wd + hr + log_dist + taxi_out + carrier_rate + prev_arr_delay - 1, data = train2)
x_valid <- model.matrix(~ wd + hr + log_dist + taxi_out + carrier_rate + prev_arr_delay - 1, data = valid2)

dtrain <- xgb.DMatrix(data = x_train, label = train2$DEP_DEL15)
dvalid <- xgb.DMatrix(data = x_valid, label = valid2$DEP_DEL15)

params <- list(
  objective        = "binary:logistic",
  eval_metric      = "auc",
  eta              = 0.05,      # halve the learning rate
  max_depth        = 4,         # keep trees shallow
  subsample        = 0.8,       # sample 80% of rows per tree
  colsample_bytree = 0.7,       # sample 70% of columns per tree
  lambda           = 1.0,       # L2 regularization
  alpha            = 0.5        # L1 regularization
)

bst <- xgb.train(
  params                = params,
  data                  = dtrain,
  nrounds               = 200,                # allow more rounds, but ES will stop early
  watchlist             = list(train=dtrain, valid=dvalid),
  early_stopping_rounds = 10,
  record                = TRUE,
  verbose               = 1
)

pred_xgb <- predict(bst, dvalid)
auc_xgb  <- auc(roc(valid2$DEP_DEL15, pred_xgb))
#cat("XGBoost AUC:", round(auc_xgb, 4), "\n")
```

```{r, fig.show='hold', out.width = "70%"}
# replot the learning curve to confirm the gap narrowed
log <- as.data.frame(bst$evaluation_log)

ggplot(log, aes(x=iter)) +
  geom_line(aes(y=train_auc, color="Train")) +
  geom_line(aes(y=valid_auc, color="Valid")) +
  labs(title="Figure 6. Regularized XGB Learning Curve",
       x="Boost Round", y="AUC") +
  scale_color_manual("",values=c("Train"="steelblue","Valid"="firebrick")) +
  geom_vline(xintercept=bst$best_iteration, linetype=2) +
  theme_minimal()
```

## 3.3 XGBoost Feature Importance and Calibration

As shown in Figure 7, the most influential feature by far was `prev_arr_delay`, contributing approximately 89% of the total gain. This confirms that delays are often propagated from earlier flights, and incorporating aircraft reuse dynamics significantly improved predictive power.

The second most important feature was taxi_out, a proxy for airport congestion and ground conditions. Other notable contributors included:

- `hr` (scheduled hour of departure), capturing time-of-day patterns,
- `carrier_rate`, reflecting historical airline performance.

Remaining predictors, including `log_dist` and `day-of-week` dummies (e.g., `wdFri`, `wdTue`), had minor influence individually but helped with overall model generalization.

Figure 8 shows that the XGBoost model is well-calibrated, with predicted probabilities aligning closely with observed delay rates across all deciles. This indicates that the model’s output probabilities are not only effective for classification (as shown by high AUC) but also provide meaningful estimates of risk. 

```{r, fig.show='hold', out.width = "70%"}
# Get feature importance
importance <- xgb.importance(model = bst)

# Plot top features
p7 <- xgb.ggplot.importance(importance_matrix = importance, top_n = 10, rel_to_first = TRUE) +
  labs(title = "Figure 7. Top Features from XGBoost Model") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))
```
```{r, fig.show='hold', out.width = "70%"}
calib_df <- tibble(
  true = valid$DEP_DEL15,
  prob = pred_xgb
) %>%
  mutate(bin = ntile(prob, 10)) %>%
  group_by(bin) %>%
  summarize(
    avg_pred = mean(prob, na.rm=TRUE),
    obs_rate = mean(true, na.rm=TRUE)
  )

p8 <- ggplot(calib_df, aes(avg_pred, obs_rate)) +
  geom_point() +
  geom_line() +
  geom_abline(linetype="dashed") +
  labs(
    title = "Figure 8. Calibration Curve",
    x     = "Mean Predicted Probability",
    y     = "Observed Delay Rate"
  ) +
  theme_minimal()
```

```{r}
library(grid)
grid.newpage()
pushViewport(viewport(layout = grid.layout(1, 2)))
print(p7, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(p8, vp = viewport(layout.pos.row = 1, layout.pos.col = 2))
```

# 4. Analysis of Results

After training and validating both logistic regression and XGBoost models, we analyzed their predictions to understand where each model excelled — and where limitations remained.

## 4.1 Analysis of Flight Prediction Performance
To better understand where tge XGBoost model excels or struggles, we stratified prediction performance by carrier, departure hour, and day of week. Overall, the model performed best on:

- Early morning flights (especially before 6 AM), where delays are less frequent and operational schedules are more predictable. Figure X shows accuracy exceeding 98% during these hours.

- Major carriers like Delta (DL) and United (UA), whose delay behavior was more stable and easier for the model to learn.

- Flights with significant inbound delays, where the inclusion of prev_arr_delay allowed the model to confidently predict late departures.

In contrast, we observed lower accuracy on:

- Late evening flights, which tend to be affected by compounding delays throughout the day.

- Low-frequency or budget carriers such as Frontier (F9) and Spirit (NK), which may operate fewer flights and exhibit more volatile patterns in delay behavior.

- Flights with no observable pre-departure issues that were nonetheless delayed due to unmodeled factors like crew availability or weather. These represent the limits of our feature space.

As visualized in Figures 9, the model’s performance is highly sensitive to both the operational context (e.g., time of day, carrier history) and the availability of predictive features (e.g., recent delay signals). While accuracy remained above 90% in most groups, the variability underscores the importance of real-time features and historical profiling in operational delay prediction.


```{r, include = FALSE}
# Add predictions to validation set
valid2 <- valid2 %>%
  mutate(pred_xgb = pred_xgb)

# Define threshold for "high confidence" prediction 
high_conf_thresh <- 0.7

# Group by factors and calculate model performance
flight_performance <- valid2 %>%
  mutate(
    pred_class = ifelse(pred_xgb > 0.5, 1, 0),
    correct    = (pred_class == DEP_DEL15)
  ) %>%
  group_by(hr = hr, carrier = carrier, wd = wd) %>%
  summarize(
    n_flights = n(),
    accuracy = mean(correct),
    avg_pred_prob = mean(pred_xgb),
    avg_actual_delay = mean(DEP_DEL15),
    .groups = "drop"
  ) %>%
  arrange(desc(accuracy))

# View top and bottom performers
flight_performance %>% arrange(accuracy) %>% head(10)   # worst prediction groups
flight_performance %>% arrange(desc(accuracy)) %>% head(10)  # best prediction groups
```

```{r, fig.show='hold', out.width = "70%"}
p5 <- flight_performance %>%
  group_by(hr) %>%
  summarize(
    avg_accuracy = mean(accuracy, na.rm = TRUE),
    n_flights = sum(n_flights)
  ) %>%
  ggplot(aes(x = hr, y = avg_accuracy)) +
    geom_line() +
    geom_point() +
    labs(
      title = "Accuracy by Scheduled Departure",
      x = "Scheduled Hour of Departure",
      y = "Average Prediction Accuracy"
    ) +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_minimal()
```


```{r, fig.show='hold', out.width = "70%"}
p6 <- flight_performance %>%
  group_by(carrier) %>%
  summarize(
    avg_accuracy = mean(accuracy, na.rm = TRUE),
    n_flights = sum(n_flights)
  ) %>%
  filter(n_flights > 5) %>%    
  ggplot(aes(x = reorder(carrier, avg_accuracy), y = avg_accuracy)) +
    geom_col(fill = "steelblue") +
    coord_flip() +
    labs(
      title = "Accuracy by Carrier",
      x = "Carrier",
      y = "Average Prediction Accuracy"
    ) +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_minimal()
```

```{r}
library(patchwork)
(p5 | p6) +
  plot_annotation(
    caption = "Figure 9. Model Accuracy by Hour (left) and by Carrier (right)",
    theme = theme(plot.caption = element_text(size = 10, hjust = 0.5))
  )
```

## 4.2 Adapting to Predict Continuous Delays Instead of AUC
If our objective shifts from predicting whether a flight is delayed (binary classification of `DEP_DEL15`) to predicting the actual delay duration in minutes (`DEP_DELAY`), this then becomes a regression problem, where the target variable is continuous. Instead of using binary classifiers and evaluating AUC, we would:

- Use a regression model such as:

  - Linear regression
  - XGBoost with `objective = "reg:squarederror"`

- Choose a loss function suited to continuous predictions:

  - Mean Squared Error (MSE): penalizes large errors more heavily
  - Mean Absolute Error (MAE): more robust to outliers

### Feature Engineering Considerations
Much of the feature engineering (e.g., `carrier_rate`, `taxi_out`, `hr`, `prev_arr_delay`) remains useful. However, for delay duration prediction:

- Greater emphasis may be placed on continuous operational variables
- Interaction terms or non-linear transformations could capture more subtle effects
- Predicting quantiles or intervals could better reflect uncertainty

### Evaluation Metrics
We would assess model quality using regression-based metrics:

- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- Possibly prediction interval coverage (e.g., for delay buffers)

## 4.3 Adapting to Minimize Cost of Missing vs Waiting

Suppose our objective is no longer to minimize classification error or AUC, but instead to minimize a real-world cost involving:
- A fixed cost \( C \) for missing a flight, and
- An hourly cost \( r \) for waiting at the airport for a delayed departure.

Rather than always arriving on time, we could use the model's predicted probability of delay to adapt our behavior:

- If the expected cost of waiting or missing is high, arrive earlier or plan alternate options.
- If the expected cost is low, follow the regular schedule.

The expected cost associated with a flight can be approximated by:

\[
\text{Expected Cost} = p(\text{delay}) \times C + (1-p(\text{delay})) \times r \times \text{Expected Delay (hours)}
\]

where \( p(\text{delay}) \) is the predicted probability of significant delay.

The optimal strategy does depend heavily on the ratio \( C/r \):

- If \( C \gg r \), missing a flight is much more costly than waiting. We would become more conservative and show up early even for modest risks of delay.
- If \( C \ll r \), waiting is very costly relative to missing, and we would be more tolerant of risk, potentially accepting higher chances of minor delays to minimize time lost.

# 5. Conclusion and Future Work

Through this project, we demonstrated that carefully engineered features, particularly those capturing real-time operational factors like aircraft reuse (`prev_arr_delay`), dramatically improve delay prediction performance. 

Our final XGBoost model achieved a validation AUC of 0.9683, substantially outperforming a logistic regression baseline (AUC 0.6884). Key lessons included the importance of incorporating lagged features, temporal patterns, and carrier-specific reliability information.

For future work, integrating real-time weather data, airport congestion statistics, and dynamic airline schedules could further enhance performance. Additionally, real-world deployment would require tuning decision thresholds based on specific operational costs and user priorities.

